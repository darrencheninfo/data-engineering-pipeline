{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student: Darren Chen\n",
    "# ADS 507 \n",
    "# Assignment 5.1  - SQL Query Performance Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel python 3.10.12 \n",
    "# Install the mysql-connector-python package\n",
    "# %pip install mysql\n",
    "# %pip install mysql-connector-python\n",
    "\n",
    "import mysql.connector \n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to Azure Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to connect to the database\n",
    "def connect_to_db(database_name):\n",
    "    db_config = {\n",
    "        \"host\": \"mysqldchen.mysql.database.azure.com\",\n",
    "        \"user\": \"dchenAdmin\",\n",
    "        \"password\": \"507password!\",\n",
    "        \"database\": database_name,\n",
    "        \"port\": 3306\n",
    "    }\n",
    "    return mysql.connector.connect(**db_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load CSV file into a DataFrame\n",
    "def load_csv(file_path):\n",
    "    df = pd.read_csv(file_path, low_memory=False)  # Avoids datatype guessing issues\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create table with optimized column types\n",
    "def create_table(conn, table_name, df):\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Define column types dynamically (optimize row size)\n",
    "    column_definitions = []\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'int64':\n",
    "            col_type = \"INT\"\n",
    "        elif df[col].dtype == 'float64':\n",
    "            col_type = \"FLOAT\"\n",
    "        elif df[col].nunique() < 255:  # If column has few unique values, use VARCHAR\n",
    "            col_type = \"VARCHAR(255)\"\n",
    "        else:\n",
    "            col_type = \"TEXT\"  # Use TEXT only when necessary\n",
    "        \n",
    "        column_definitions.append(f\"`{col}` {col_type}\")\n",
    "    \n",
    "    columns_str = \",\\n    \".join(column_definitions)\n",
    "\n",
    "    create_table_query = f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS `{table_name}` (\n",
    "        {columns_str}\n",
    "    ) ENGINE=InnoDB ROW_FORMAT=DYNAMIC;\n",
    "    \"\"\"\n",
    "\n",
    "    cursor.execute(create_table_query)\n",
    "    conn.commit()\n",
    "    cursor.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to insert data into MySQL\n",
    "def insert_data(conn, table_name, df):\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Prepare insert query\n",
    "    columns = \", \".join([f\"`{col}`\" for col in df.columns])\n",
    "    placeholders = \", \".join([\"%s\"] * len(df.columns))\n",
    "    insert_query = f\"INSERT INTO `{table_name}` ({columns}) VALUES ({placeholders})\"\n",
    "\n",
    "    # Convert DataFrame rows to list of tuples\n",
    "    data = [tuple(row) for row in df.itertuples(index=False, name=None)]\n",
    "\n",
    "    try:\n",
    "        cursor.executemany(insert_query, data)\n",
    "        conn.commit()\n",
    "    except mysql.connector.Error as e:\n",
    "        print(\"Error inserting data:\", e)\n",
    "\n",
    "    cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded into MySQL database.\n"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "db_name = \"icpsr_03088\"\n",
    "table_name = \"adss_data_part1\"\n",
    "csv_file_path = \"C:\\\\Users\\\\darre\\\\OneDrive\\\\Documents\\\\ADS\\\\ADS 507 Data Engineering\\\\data\\\\ICPSR_03088\\\\DS0001\\\\03088-0001-Data.csv\" \n",
    "\n",
    "# Connect to MySQL database\n",
    "conn = connect_to_db(db_name)\n",
    "\n",
    "# Load CSV data\n",
    "df = load_csv(csv_file_path)\n",
    "\n",
    "# Create optimized table\n",
    "create_table(conn, table_name, df)\n",
    "\n",
    "# Insert data\n",
    "insert_data(conn, table_name, df)\n",
    "\n",
    "# Close connection\n",
    "conn.close()\n",
    "\n",
    "print(\"Data successfully loaded into MySQL database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to execute SQL queries\n",
    "def run_query(query):\n",
    "    # try: (indent next for error handling)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(query)\n",
    "    results = cursor.fetchall()\n",
    "    for row in results:\n",
    "        print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to insert data from DataFrame into MySQL table\n",
    "def insert_data(conn, table_name, df):\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Construct the SQL INSERT statement dynamically\n",
    "    columns = \", \".join([f\"`{col}`\" for col in df.columns])\n",
    "    placeholders = \", \".join([\"%s\"] * len(df.columns))\n",
    "    \n",
    "    insert_query = f\"INSERT INTO `{table_name}` ({columns}) VALUES ({placeholders})\"\n",
    "    \n",
    "    # Convert DataFrame to a list of tuples for batch insert\n",
    "    data = [tuple(row) for row in df.to_numpy()]\n",
    "    \n",
    "    # Execute batch insert\n",
    "    cursor.executemany(insert_query, data)\n",
    "    conn.commit()\n",
    "    \n",
    "    cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to Get data types\n",
    "def get_data_types(df):\n",
    "    columns = df.columns\n",
    "    data_types = df.dtypes\n",
    "\n",
    "    return df.dtypes.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "1118 (42000): Row size too large (> 8126). Changing some columns to TEXT or BLOB may help. In current row format, BLOB prefix of 0 bytes is stored inline.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m df \u001b[38;5;241m=\u001b[39m load_csv(csv_file_path)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Create table if not exists\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m create_table(conn, table_name, df)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Insert data into the table\u001b[39;00m\n\u001b[0;32m     17\u001b[0m insert_data(conn, table_name, df)\n",
      "Cell \u001b[1;32mIn[9], line 14\u001b[0m, in \u001b[0;36mcreate_table\u001b[1;34m(conn, table_name, df)\u001b[0m\n\u001b[0;32m      6\u001b[0m columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` TEXT\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns])\n\u001b[0;32m      8\u001b[0m create_table_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124mCREATE TABLE IF NOT EXISTS `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` (\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumns\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124m);\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 14\u001b[0m cursor\u001b[38;5;241m.\u001b[39mexecute(create_table_query)\n\u001b[0;32m     15\u001b[0m conn\u001b[38;5;241m.\u001b[39mcommit()\n\u001b[0;32m     16\u001b[0m cursor\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\cursor.py:416\u001b[0m, in \u001b[0;36mMySQLCursor.execute\u001b[1;34m(self, operation, params, map_results)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executed_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stmt_partition[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle_stmts\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executed \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stmt_partition[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle_stmts\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mpopleft()\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m map_results\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stmt_partition[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmappable_stmt\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    413\u001b[0m )\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_result(\n\u001b[1;32m--> 416\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mcmd_query(\n\u001b[0;32m    417\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stmt_partition[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmappable_stmt\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    418\u001b[0m         read_timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_timeout,\n\u001b[0;32m    419\u001b[0m         write_timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_timeout,\n\u001b[0;32m    420\u001b[0m     )\n\u001b[0;32m    421\u001b[0m )\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\opentelemetry\\context_propagation.py:106\u001b[0m, in \u001b[0;36mwith_context_propagation.<locals>.wrapper\u001b[1;34m(cnx, *args, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m     cnx\u001b[38;5;241m.\u001b[39mquery_attrs_append(value\u001b[38;5;241m=\u001b[39m(TRACEPARENT_HEADER_NAME, tp_header))\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 106\u001b[0m     result \u001b[38;5;241m=\u001b[39m method(cnx, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tp_header \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\utils.py:742\u001b[0m, in \u001b[0;36mhandle_read_write_timeout.<locals>.decorator.<locals>.handle_cnx_method\u001b[1;34m(cnx, *args, **kwargs)\u001b[0m\n\u001b[0;32m    740\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, \u001b[38;5;167;01mTimeoutError\u001b[39;00m):\n\u001b[0;32m    741\u001b[0m     cnx\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m--> 742\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\utils.py:738\u001b[0m, in \u001b[0;36mhandle_read_write_timeout.<locals>.decorator.<locals>.handle_cnx_method\u001b[1;34m(cnx, *args, **kwargs)\u001b[0m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(cnx_method)\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhandle_cnx_method\u001b[39m(\n\u001b[0;32m    735\u001b[0m     cnx: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMySQLConnectionAbstract\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[0;32m    736\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 738\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cnx_method(cnx, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    739\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    740\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, \u001b[38;5;167;01mTimeoutError\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\connection.py:937\u001b[0m, in \u001b[0;36mMySQLConnection.cmd_query\u001b[1;34m(self, query, raw, buffered, raw_as_string, **kwargs)\u001b[0m\n\u001b[0;32m    934\u001b[0m     read_timeout \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread_timeout\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    935\u001b[0m     write_timeout \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwrite_timeout\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 937\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_result(\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_cmd(\n\u001b[0;32m    939\u001b[0m             ServerCmd\u001b[38;5;241m.\u001b[39mQUERY,\n\u001b[0;32m    940\u001b[0m             query,\n\u001b[0;32m    941\u001b[0m             read_timeout\u001b[38;5;241m=\u001b[39mread_timeout,\n\u001b[0;32m    942\u001b[0m             write_timeout\u001b[38;5;241m=\u001b[39mwrite_timeout,\n\u001b[0;32m    943\u001b[0m         ),\n\u001b[0;32m    944\u001b[0m         read_timeout,\n\u001b[0;32m    945\u001b[0m         write_timeout,\n\u001b[0;32m    946\u001b[0m     )\n\u001b[0;32m    947\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ProgrammingError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    948\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m err\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3948\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading local data is disabled\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m err\u001b[38;5;241m.\u001b[39mmsg:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\utils.py:742\u001b[0m, in \u001b[0;36mhandle_read_write_timeout.<locals>.decorator.<locals>.handle_cnx_method\u001b[1;34m(cnx, *args, **kwargs)\u001b[0m\n\u001b[0;32m    740\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, \u001b[38;5;167;01mTimeoutError\u001b[39;00m):\n\u001b[0;32m    741\u001b[0m     cnx\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m--> 742\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\utils.py:738\u001b[0m, in \u001b[0;36mhandle_read_write_timeout.<locals>.decorator.<locals>.handle_cnx_method\u001b[1;34m(cnx, *args, **kwargs)\u001b[0m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(cnx_method)\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhandle_cnx_method\u001b[39m(\n\u001b[0;32m    735\u001b[0m     cnx: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMySQLConnectionAbstract\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[0;32m    736\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 738\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cnx_method(cnx, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    739\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    740\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, \u001b[38;5;167;01mTimeoutError\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\connection.py:703\u001b[0m, in \u001b[0;36mMySQLConnection._handle_result\u001b[1;34m(self, packet, read_timeout, write_timeout)\u001b[0m\n\u001b[0;32m    701\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_eof(packet)\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m packet[\u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m255\u001b[39m:\n\u001b[1;32m--> 703\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m get_exception(packet)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# We have a text result set\u001b[39;00m\n\u001b[0;32m    706\u001b[0m column_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_protocol\u001b[38;5;241m.\u001b[39mparse_column_count(packet)\n",
      "\u001b[1;31mProgrammingError\u001b[0m: 1118 (42000): Row size too large (> 8126). Changing some columns to TEXT or BLOB may help. In current row format, BLOB prefix of 0 bytes is stored inline."
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "db_name = \"icpsr_03088\"\n",
    "table_name = \"adss_data_part1\"\n",
    "csv_file_path = \"/path/to/03088-0001-Data.csv\"  # Change this to your actual file path\n",
    "\n",
    "# Connect to MySQL database\n",
    "conn = connect_to_db(db_name)\n",
    "\n",
    "# Load CSV data\n",
    "csv_file_path = \"C:\\\\Users\\\\darre\\\\OneDrive\\\\Documents\\\\ADS\\\\ADS 507 Data Engineering\\\\data\\\\ICPSR_03088\\\\DS0001\\\\03088-0001-Data.csv\"\n",
    "df = load_csv(csv_file_path)\n",
    "\n",
    "# Create table if not exists\n",
    "create_table(conn, table_name, df)\n",
    "\n",
    "# Insert data into the table\n",
    "insert_data(conn, table_name, df)\n",
    "\n",
    "# Close connection\n",
    "conn.close()\n",
    "\n",
    "print(\"Data successfully loaded into MySQL database.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(db_name, table_name, df):\n",
    "    \"\"\" DOCSTRING: Creates a table in the database with the specified columns and data types.\n",
    "\n",
    "    Args:\n",
    "        db_name (str): Name of the database.\n",
    "        table_name (str): Name of the table to be created.\n",
    "        columns (list of str): List of column names for the table.\n",
    "        data_types (list of str): Corresponding data types for each column.\n",
    "        primary_keys (list of str): List of columns to set as primary keys.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    columns = get_columns(df)\n",
    "    data_types = get_data_types(df)\n",
    "    \n",
    "    conn = connect_to_db(db_name)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "        # Mapping pandas dtypes to MySQL column types\n",
    "    dtype_mapping = {\n",
    "        \"int64\": \"INT\",\n",
    "        \"float64\": \"FLOAT\",\n",
    "        \"object\": \"VARCHAR(255)\",  # Ensure strings are VARCHAR instead of TEXT\n",
    "        \"bool\": \"BOOLEAN\"\n",
    "    }\n",
    "    \n",
    "    # Construct SQL query\n",
    "    create_table_query = f\"CREATE TABLE IF NOT EXISTS {table_name} (\"\n",
    "    for col, dtype in zip(columns, data_types):\n",
    "        sql_type = dtype_mapping.get(dtype, \"TEXT\")\n",
    "        create_table_query += f\"`{col}` {sql_type}, \"\n",
    "    \n",
    "    \n",
    "    # Execute SQL query\n",
    "    cursor.execute(create_table_query)\n",
    "    \n",
    "    # Commit and close connection\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load ICPSR DATA PART 1 TO DATABASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '' at line 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m df \u001b[38;5;241m=\u001b[39m load_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mdarre\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mOneDrive\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mADS\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mADS 507 Data Engineering\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mICPSR_03088\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDS0001\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m03088-0001-Data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# create_table(db_name, table_name, df)\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m create_table(db_name, table_name, df)\n",
      "Cell \u001b[1;32mIn[8], line 36\u001b[0m, in \u001b[0;36mcreate_table\u001b[1;34m(db_name, table_name, df)\u001b[0m\n\u001b[0;32m     32\u001b[0m     create_table_query \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Execute SQL query\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m cursor\u001b[38;5;241m.\u001b[39mexecute(create_table_query)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Commit and close connection\u001b[39;00m\n\u001b[0;32m     39\u001b[0m conn\u001b[38;5;241m.\u001b[39mcommit()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\cursor.py:416\u001b[0m, in \u001b[0;36mMySQLCursor.execute\u001b[1;34m(self, operation, params, map_results)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executed_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stmt_partition[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle_stmts\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executed \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stmt_partition[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle_stmts\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mpopleft()\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m map_results\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stmt_partition[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmappable_stmt\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    413\u001b[0m )\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_result(\n\u001b[1;32m--> 416\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mcmd_query(\n\u001b[0;32m    417\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stmt_partition[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmappable_stmt\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    418\u001b[0m         read_timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_timeout,\n\u001b[0;32m    419\u001b[0m         write_timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_timeout,\n\u001b[0;32m    420\u001b[0m     )\n\u001b[0;32m    421\u001b[0m )\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\opentelemetry\\context_propagation.py:106\u001b[0m, in \u001b[0;36mwith_context_propagation.<locals>.wrapper\u001b[1;34m(cnx, *args, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m     cnx\u001b[38;5;241m.\u001b[39mquery_attrs_append(value\u001b[38;5;241m=\u001b[39m(TRACEPARENT_HEADER_NAME, tp_header))\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 106\u001b[0m     result \u001b[38;5;241m=\u001b[39m method(cnx, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tp_header \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\utils.py:742\u001b[0m, in \u001b[0;36mhandle_read_write_timeout.<locals>.decorator.<locals>.handle_cnx_method\u001b[1;34m(cnx, *args, **kwargs)\u001b[0m\n\u001b[0;32m    740\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, \u001b[38;5;167;01mTimeoutError\u001b[39;00m):\n\u001b[0;32m    741\u001b[0m     cnx\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m--> 742\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\utils.py:738\u001b[0m, in \u001b[0;36mhandle_read_write_timeout.<locals>.decorator.<locals>.handle_cnx_method\u001b[1;34m(cnx, *args, **kwargs)\u001b[0m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(cnx_method)\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhandle_cnx_method\u001b[39m(\n\u001b[0;32m    735\u001b[0m     cnx: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMySQLConnectionAbstract\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[0;32m    736\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 738\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cnx_method(cnx, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    739\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    740\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, \u001b[38;5;167;01mTimeoutError\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\connection.py:937\u001b[0m, in \u001b[0;36mMySQLConnection.cmd_query\u001b[1;34m(self, query, raw, buffered, raw_as_string, **kwargs)\u001b[0m\n\u001b[0;32m    934\u001b[0m     read_timeout \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread_timeout\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    935\u001b[0m     write_timeout \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwrite_timeout\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 937\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_result(\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_cmd(\n\u001b[0;32m    939\u001b[0m             ServerCmd\u001b[38;5;241m.\u001b[39mQUERY,\n\u001b[0;32m    940\u001b[0m             query,\n\u001b[0;32m    941\u001b[0m             read_timeout\u001b[38;5;241m=\u001b[39mread_timeout,\n\u001b[0;32m    942\u001b[0m             write_timeout\u001b[38;5;241m=\u001b[39mwrite_timeout,\n\u001b[0;32m    943\u001b[0m         ),\n\u001b[0;32m    944\u001b[0m         read_timeout,\n\u001b[0;32m    945\u001b[0m         write_timeout,\n\u001b[0;32m    946\u001b[0m     )\n\u001b[0;32m    947\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ProgrammingError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    948\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m err\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3948\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading local data is disabled\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m err\u001b[38;5;241m.\u001b[39mmsg:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\utils.py:742\u001b[0m, in \u001b[0;36mhandle_read_write_timeout.<locals>.decorator.<locals>.handle_cnx_method\u001b[1;34m(cnx, *args, **kwargs)\u001b[0m\n\u001b[0;32m    740\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, \u001b[38;5;167;01mTimeoutError\u001b[39;00m):\n\u001b[0;32m    741\u001b[0m     cnx\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m--> 742\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\utils.py:738\u001b[0m, in \u001b[0;36mhandle_read_write_timeout.<locals>.decorator.<locals>.handle_cnx_method\u001b[1;34m(cnx, *args, **kwargs)\u001b[0m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(cnx_method)\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhandle_cnx_method\u001b[39m(\n\u001b[0;32m    735\u001b[0m     cnx: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMySQLConnectionAbstract\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[0;32m    736\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 738\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cnx_method(cnx, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    739\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    740\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, \u001b[38;5;167;01mTimeoutError\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\connection.py:703\u001b[0m, in \u001b[0;36mMySQLConnection._handle_result\u001b[1;34m(self, packet, read_timeout, write_timeout)\u001b[0m\n\u001b[0;32m    701\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_eof(packet)\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m packet[\u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m255\u001b[39m:\n\u001b[1;32m--> 703\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m get_exception(packet)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# We have a text result set\u001b[39;00m\n\u001b[0;32m    706\u001b[0m column_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_protocol\u001b[38;5;241m.\u001b[39mparse_column_count(packet)\n",
      "\u001b[1;31mProgrammingError\u001b[0m: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '' at line 1"
     ]
    }
   ],
   "source": [
    "# create a connection to the db and create a table from csv file\n",
    "\n",
    "db_name = \"icpsr_03088\"\n",
    "connect_to_db(db_name)\n",
    "\n",
    "# get the table name \n",
    "table_name = \"adss_data_part1\"\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = load_csv(\"C:\\\\Users\\\\darre\\\\OneDrive\\\\Documents\\\\ADS\\\\ADS 507 Data Engineering\\\\data\\\\ICPSR_03088\\\\DS0001\\\\03088-0001-Data.csv\")\n",
    "\n",
    "# create_table(db_name, table_name, df)\n",
    "create_table(db_name, table_name, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load ADSS data to sql datab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ETL DATA: Alcohol and Drug Services Study (ADSS), 1996-1999: [United States] (ICPSR 3088)\n",
    "LINK: https://www.icpsr.umich.edu/web/NAHDAP/studies/3088/export\n",
    "DOWNLOAD DELIMITED FILE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert TSV to CSV\n",
    "\n",
    "# Define the file paths \n",
    "tsv_file_path = r'C:\\Users\\darre\\OneDrive\\Documents\\ADS\\ADS 507 Data Engineering\\data\\ICPSR_03088\\DS0003\\03088-0003-Data.tsv'\n",
    "csv_file_path = r'C:\\Users\\darre\\OneDrive\\Documents\\ADS\\ADS 507 Data Engineering\\data\\ICPSR_03088\\DS0003\\03088-0003-Data.csv'\n",
    "\n",
    "# Open the TSV file for reading and the CSV file for writing\n",
    "with open(tsv_file_path, 'r', newline='', encoding='utf-8') as tsv_file, \\\n",
    "     open(csv_file_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "    \n",
    "    # Create a TSV reader and a CSV writer\n",
    "    tsv_reader = csv.reader(tsv_file, delimiter='\\t')\n",
    "    csv_writer = csv.writer(csv_file, delimiter=',')\n",
    "\n",
    "    # Iterate over each row in the TSV file and write it to the CSV file\n",
    "    for row in tsv_reader:\n",
    "        csv_writer.writerow(row)\n",
    "\n",
    "print(f\"TSV file has been successfully converted to CSV and saved at: {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert tsv file to csv for import to mysql database: \n",
    "\n",
    "in VSCode Terminal enter the following to convert to csv:  \n",
    ">Import-Csv -Delimiter \"`t\" -Path \"C:\\Users\\darre\\OneDrive\\Documents\\ADS\\ADS 507 Data Engineering\\data\\ICPSR_03088\\DS0004\\03088-0004-Data.tsv\" | Export-Csv -NoTypeInformation -Path \"C:\\Users\\darre\\OneDrive\\Documents\\ADS\\ADS 507 Data Engineering\\data\\ICPSR_03088\\DS0004\\03088-0004-Data.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ICPSR_03088  Alcohol and Drug Services Study (ADSS)\n",
    "\n",
    "Part 3 - Phase 2 - Main Incentive Abstract data table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'group' has been removed.\n",
      "Updated file saved as: C:\\Users\\darre\\OneDrive\\Documents\\ADS\\ADS 507 Data Engineering\\data\\ICPSR_03088\\DS0003\\03088-0003-Data_updated.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define file path\n",
    "csv_file = \"C:\\\\Users\\\\darre\\\\OneDrive\\\\Documents\\\\ADS\\\\ADS 507 Data Engineering\\\\data\\\\ICPSR_03088\\\\DS0003\\\\03088-0003-Data.csv\"\n",
    "\n",
    "# Load CSV into DataFrame\n",
    "df_part3 = pd.read_csv(csv_file)\n",
    "\n",
    "# Check if 'group' column exists before dropping\n",
    "if 'group' in df_part3.columns:\n",
    "    df_part3 = df_part3.drop(columns=['group'])\n",
    "    print(\"Column 'group' has been removed.\")\n",
    "else:\n",
    "    print(\"Column 'group' not found in the dataset.\")\n",
    "\n",
    "# Save updated DataFrame to a new CSV file\n",
    "output_file = csv_file.replace(\".csv\", \"_updated.csv\")\n",
    "df_part3.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Updated file saved as: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded into MySQL database.\n"
     ]
    }
   ],
   "source": [
    "# import mysql.connector\n",
    "# import pandas as pd\n",
    "\n",
    "# Database connection details\n",
    "db_config = {\n",
    "    \"host\": \"mysqldchen.mysql.database.azure.com\",\n",
    "    \"user\": \"dchenAdmin\",\n",
    "    \"port\": 3306,\n",
    "    \"password\": \"507password!\",\n",
    "    \"database\": \"icpsr_03088\"\n",
    "}\n",
    "\n",
    "# Connect to MySQL database\n",
    "conn = mysql.connector.connect(**db_config)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Generate table name\n",
    "table_name = \"adss_data_part3\"\n",
    "\n",
    "# Define file path\n",
    "csv_file = \"C:\\\\Users\\\\darre\\\\OneDrive\\\\Documents\\\\ADS\\\\ADS 507 Data Engineering\\\\data\\\\ICPSR_03088\\\\DS0003\\\\03088-0003-Data_updated.csv\"\n",
    "\n",
    "# Load CSV into DataFrame\n",
    "df_part3 = pd.read_csv(csv_file)\n",
    "\n",
    "# Get column names and data types\n",
    "columns = df_part3.columns\n",
    "data_types = df_part3.dtypes\n",
    "\n",
    "# Mapping pandas dtypes to MySQL column types\n",
    "dtype_mapping = {\n",
    "    \"int64\": \"INT\",\n",
    "    \"float64\": \"FLOAT\",\n",
    "    \"object\": \"TEXT\",\n",
    "    \"bool\": \"BOOLEAN\"\n",
    "}\n",
    "\n",
    "# Define the table schema with caseid and facid as PRIMARY KEYS\n",
    "create_table_query = f\"CREATE TABLE IF NOT EXISTS {table_name} (\"\n",
    "for col, dtype in zip(columns, data_types):\n",
    "    mysql_type = dtype_mapping.get(str(dtype), \"TEXT\")  # Default to TEXT if unknown\n",
    "    create_table_query += f\"`{col}` {mysql_type}, \"\n",
    "\n",
    "# Define composite primary key (caseid, facid)\n",
    "create_table_query += \"PRIMARY KEY (`caseid`, `facid`));\"\n",
    "\n",
    "# Execute the table creation query\n",
    "cursor.execute(create_table_query)\n",
    "conn.commit()\n",
    "\n",
    "# Insert data into the table\n",
    "insert_query = f\"INSERT IGNORE INTO {table_name} ({', '.join(columns)}) VALUES ({', '.join(['%s'] * len(columns))})\"\n",
    "# iteratively adds rows to the table\n",
    "for _, row in df_part3.iterrows():\n",
    "    cursor.execute(insert_query, tuple(row))\n",
    "\n",
    "# Commit and close the connection\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"Data successfully loaded into MySQL database.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ICPSR_03088  Alcohol and Drug Services Study (ADSS)\n",
    "\n",
    "Part 4 - Phase 2 - In-Treatment Methadone Abstract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'group' has been removed.\n",
      "Updated file saved as: C:\\Users\\darre\\OneDrive\\Documents\\ADS\\ADS 507 Data Engineering\\data\\ICPSR_03088\\DS0004\\03088-0004-Data_updated.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define file path\n",
    "csv_file = \"C:\\\\Users\\\\darre\\\\OneDrive\\\\Documents\\\\ADS\\\\ADS 507 Data Engineering\\\\data\\\\ICPSR_03088\\\\DS0004\\\\03088-0004-Data.csv\"\n",
    "\n",
    "# Load CSV into DataFrame\n",
    "df_part4 = pd.read_csv(csv_file)\n",
    "\n",
    "# Check if 'group' column exists before dropping\n",
    "if 'group' in df_part4.columns:\n",
    "    df_part4 = df_part4.drop(columns=['group'])\n",
    "    print(\"Column 'group' has been removed.\")\n",
    "else:\n",
    "    print(\"Column 'group' not found in the dataset.\")\n",
    "\n",
    "# Save updated DataFrame to a new CSV file\n",
    "output_file = csv_file.replace(\".csv\", \"_updated.csv\")\n",
    "df_part4.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Updated file saved as: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD PART 7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded into MySQL database.\n"
     ]
    }
   ],
   "source": [
    "# Database connection details\n",
    "db_config = {\n",
    "    \"host\": \"mysqldchen.mysql.database.azure.com\",\n",
    "    \"user\": \"dchenAdmin\",\n",
    "    \"port\": 3306,\n",
    "    \"password\": \"507password!\",\n",
    "    \"database\": \"icpsr_03088\"\n",
    "}\n",
    "\n",
    "# Connect to MySQL database\n",
    "conn = mysql.connector.connect(**db_config)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Generate table name\n",
    "table_name = \"adss_data_part4\"\n",
    "\n",
    "# Define file path\n",
    "csv_file = \"C:\\\\Users\\\\darre\\\\OneDrive\\\\Documents\\\\ADS\\\\ADS 507 Data Engineering\\\\data\\\\ICPSR_03088\\\\DS0004\\\\03088-0004-Data_updated.csv\"\n",
    "\n",
    "# Load CSV into DataFrame\n",
    "df_part4 = pd.read_csv(csv_file)\n",
    "\n",
    "# Get column names and data types\n",
    "columns = df_part4.columns\n",
    "data_types = df_part4.dtypes\n",
    "\n",
    "# Mapping pandas dtypes to MySQL column types\n",
    "dtype_mapping = {\n",
    "    \"int64\": \"INT\",\n",
    "    \"float64\": \"FLOAT\",\n",
    "    \"object\": \"TEXT\",\n",
    "    \"bool\": \"BOOLEAN\"\n",
    "}\n",
    "\n",
    "# Define the table schema with caseid and facid as PRIMARY KEYS\n",
    "create_table_query = f\"CREATE TABLE IF NOT EXISTS {table_name} (\"\n",
    "for col, dtype in zip(columns, data_types):\n",
    "    mysql_type = dtype_mapping.get(str(dtype), \"TEXT\")  # Default to TEXT if unknown\n",
    "    create_table_query += f\"`{col}` {mysql_type}, \"\n",
    "\n",
    "# Define composite primary key (caseid, facid)\n",
    "create_table_query += \"PRIMARY KEY (`caseid`, `facid`));\"\n",
    "\n",
    "# Execute the table creation query\n",
    "cursor.execute(create_table_query)\n",
    "conn.commit()\n",
    "\n",
    "# Insert data into the table\n",
    "insert_query = f\"INSERT IGNORE INTO {table_name} ({', '.join(columns)}) VALUES ({', '.join(['%s'] * len(columns))})\"\n",
    "# iteratively adds rows to the table\n",
    "for _, row in df_part4.iterrows():\n",
    "    cursor.execute(insert_query, tuple(row))\n",
    "\n",
    "# Commit and close the connection\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"Data successfully loaded into MySQL database.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ICPSR_03088  Alcohol and Drug Services Study (ADSS)\n",
    "\n",
    "Part 7 - Phase 3 - Follow-up Survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'group' has been removed.\n",
      "Updated file saved as: C:\\Users\\darre\\OneDrive\\Documents\\ADS\\ADS 507 Data Engineering\\data\\ICPSR_03088\\DS0007\\03088-0007-Data_updated.csv\n"
     ]
    }
   ],
   "source": [
    "# Load the data from tsv and remove column named 'group'\n",
    "# Define file path\n",
    "csv_file = \"C:\\\\Users\\\\darre\\\\OneDrive\\\\Documents\\\\ADS\\\\ADS 507 Data Engineering\\\\data\\\\ICPSR_03088\\\\DS0007\\\\03088-0007-Data.csv\"\n",
    "\n",
    "# Load CSV into DataFrame\n",
    "df_part7 = pd.read_csv(csv_file)\n",
    "\n",
    "# Check if 'group' column exists before dropping\n",
    "if 'group' in df_part7.columns:\n",
    "    df_part7 = df_part7.drop(columns=['group'])\n",
    "    print(\"Column 'group' has been removed.\")\n",
    "else:\n",
    "    print(\"Column 'group' not found in the dataset.\")\n",
    "\n",
    "# Save updated DataFrame to a new CSV file\n",
    "output_file = csv_file.replace(\".csv\", \"_updated.csv\")\n",
    "df_part7.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Updated file saved as: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded into MySQL database.\n"
     ]
    }
   ],
   "source": [
    "# Database connection details\n",
    "db_config = {\n",
    "    \"host\": \"mysqldchen.mysql.database.azure.com\",\n",
    "    \"user\": \"dchenAdmin\",\n",
    "    \"port\": 3306,\n",
    "    \"password\": \"507password!\",\n",
    "    \"database\": \"icpsr_03088\"\n",
    "}\n",
    "\n",
    "# Connect to MySQL database\n",
    "conn = mysql.connector.connect(**db_config)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Generate table name\n",
    "table_name = \"adss_data_part7\"\n",
    "\n",
    "# Define file path\n",
    "csv_file = \"C:\\\\Users\\\\darre\\\\OneDrive\\\\Documents\\\\ADS\\\\ADS 507 Data Engineering\\\\data\\\\ICPSR_03088\\\\DS0007\\\\03088-0007-Data_updated.csv\"\n",
    "\n",
    "# Load CSV into DataFrame\n",
    "df_part7 = pd.read_csv(csv_file)\n",
    "\n",
    "# Get column names and data types\n",
    "columns = df_part7.columns\n",
    "data_types = df_part7.dtypes\n",
    "\n",
    "# Mapping pandas dtypes to MySQL column types\n",
    "dtype_mapping = {\n",
    "    \"int64\": \"INT\",\n",
    "    \"float64\": \"FLOAT\",\n",
    "    \"object\": \"TEXT\",\n",
    "    \"bool\": \"BOOLEAN\"\n",
    "}\n",
    "\n",
    "# Define the table schema with caseid and facid as PRIMARY KEYS\n",
    "create_table_query = f\"CREATE TABLE IF NOT EXISTS {table_name} (\"\n",
    "for col, dtype in zip(columns, data_types):\n",
    "    mysql_type = dtype_mapping.get(str(dtype), \"TEXT\")  # Default to TEXT if unknown\n",
    "    create_table_query += f\"`{col}` {mysql_type}, \"\n",
    "\n",
    "# Define composite primary key (caseid, facid)\n",
    "create_table_query += \"PRIMARY KEY (`caseid`, `facid`));\"\n",
    "\n",
    "# Execute the table creation query\n",
    "cursor.execute(create_table_query)\n",
    "conn.commit()\n",
    "\n",
    "# Insert data into the table\n",
    "insert_query = f\"INSERT IGNORE INTO {table_name} ({', '.join(columns)}) VALUES ({', '.join(['%s'] * len(columns))})\"\n",
    "# iteratively adds rows to the table\n",
    "for _, row in df_part7.iterrows():\n",
    "    cursor.execute(insert_query, tuple(row))\n",
    "\n",
    "# Commit and close the connection\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"Data successfully loaded into MySQL database.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "database: cdcyrbss   \n",
    "CDC - Youth Risk Behavior Surveillance System (YRBSS) \n",
    "\n",
    "creating schema, and importing data \n",
    "\n",
    "primary key = 'CASEID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\darre\\AppData\\Local\\Temp\\ipykernel_39376\\3460893445.py:21: DtypeWarning: Columns (2,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data successfully loaded into MySQL database.\n"
     ]
    }
   ],
   "source": [
    "# 3ector\n",
    "# import pandas as pd \n",
    "\n",
    "# Database connection details \n",
    "db_config = {\n",
    "    \"host\": \"mysqldchen.mysql.database.azure.com\",\n",
    "    \"user\": \"dchenAdmin\",\n",
    "    \"port\": 3306,\n",
    "    \"password\": \"507password!\",\n",
    "    \"database\": \"cdcyrbss\"\n",
    "}\n",
    "\n",
    "# Connect to MySQL database\n",
    "conn = mysql.connector.connect(**db_config)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Load CSV file\n",
    "csv_file = r\"C:\\Users\\darre\\OneDrive\\Documents\\ADS\\ADS 507 Data Engineering\\data\\CDC\\XXHq.csv\"\n",
    "\n",
    "# Read CSV into pandas DataFrame\n",
    "cdcyrbss_df = pd.read_csv(csv_file)\n",
    "\n",
    "# Convert column names to lowercase and remove spaces for compatibility\n",
    "cdcyrbss_df.columns = cdcyrbss_df.columns.str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "# Table name\n",
    "table_name = \"national2021\"\n",
    "\n",
    "# Get column names and data types\n",
    "columns = cdcyrbss_df.columns\n",
    "data_types = cdcyrbss_df.dtypes\n",
    "\n",
    "# Mapping pandas dtypes to MySQL column types\n",
    "dtype_mapping = {\n",
    "    \"int64\": \"INT\",\n",
    "    \"float64\": \"FLOAT\",\n",
    "    \"object\": \"TEXT\",\n",
    "    \"bool\": \"BOOLEAN\"\n",
    "}\n",
    "\n",
    "# Define the table schema dynamically\n",
    "create_table_query = f\"CREATE TABLE IF NOT EXISTS {table_name} (\"\n",
    "column_definitions = []\n",
    "\n",
    "for col, dtype in zip(columns, data_types):\n",
    "    mysql_type = dtype_mapping.get(str(dtype), \"TEXT\")  # Default to TEXT if unknown\n",
    "    column_definitions.append(f\"`{col}` {mysql_type}\")\n",
    "\n",
    "# Add primary key (caseid)\n",
    "column_definitions.append(\"PRIMARY KEY (`record`)\")\n",
    "create_table_query += \", \".join(column_definitions) + \");\"\n",
    "\n",
    "# Execute the table creation query\n",
    "cursor.execute(create_table_query)\n",
    "conn.commit()\n",
    "\n",
    "# Insert data into the table\n",
    "insert_query = f\"INSERT IGNORE INTO {table_name} ({', '.join(columns)}) VALUES ({', '.join(['%s'] * len(columns))})\"\n",
    "\n",
    "for _, row in cdcyrbss_df.iterrows():\n",
    "    cursor.execute(insert_query, tuple(row))\n",
    "\n",
    "# Commit and close the connection\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\" Data successfully loaded into MySQL database.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'group' has been removed.\n",
      "Updated file saved as: C:\\Users\\darre\\OneDrive\\Documents\\ADS\\ADS 507 Data Engineering\\data\\ICPSR_03088\\DS0004\\03088-0004-Data_updated.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define file path\n",
    "csv_file = \"C:\\\\Users\\\\darre\\\\OneDrive\\\\Documents\\\\ADS\\\\ADS 507 Data Engineering\\\\data\\\\ICPSR_03088\\\\DS0004\\\\03088-0004-Data.csv\"\n",
    "\n",
    "# Load CSV into DataFrame\n",
    "df_part4 = pd.read_csv(csv_file)\n",
    "\n",
    "# Check if 'group' column exists before dropping\n",
    "if 'group' in df_part4.columns:\n",
    "    df_part4 = df_part4.drop(columns=['group'])\n",
    "    print(\"Column 'group' has been removed.\")\n",
    "else:\n",
    "    print(\"Column 'group' not found in the dataset.\")\n",
    "\n",
    "# Save updated DataFrame to a new CSV file\n",
    "output_file = csv_file.replace(\".csv\", \"_updated.csv\")\n",
    "df_part4.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Updated file saved as: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded into MySQL database.\n"
     ]
    }
   ],
   "source": [
    "# Database connection details\n",
    "db_config = {\n",
    "    \"host\": \"mysqldchen.mysql.database.azure.com\",\n",
    "    \"user\": \"dchenAdmin\",\n",
    "    \"port\": 3306,\n",
    "    \"password\": \"507password!\",\n",
    "    \"database\": \"icpsr_03088\"\n",
    "}\n",
    "\n",
    "# Connect to MySQL database\n",
    "conn = mysql.connector.connect(**db_config)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Generate table name\n",
    "table_name = \"adss_data_part4\"\n",
    "\n",
    "# Define file path\n",
    "csv_file = \"C:\\\\Users\\\\darre\\\\OneDrive\\\\Documents\\\\ADS\\\\ADS 507 Data Engineering\\\\data\\\\ICPSR_03088\\\\DS0004\\\\03088-0004-Data_updated.csv\"\n",
    "\n",
    "# Load CSV into DataFrame\n",
    "df_part4 = pd.read_csv(csv_file)\n",
    "\n",
    "# Get column names and data types\n",
    "columns = df_part4.columns\n",
    "data_types = df_part4.dtypes\n",
    "\n",
    "# Mapping pandas dtypes to MySQL column types\n",
    "dtype_mapping = {\n",
    "    \"int64\": \"INT\",\n",
    "    \"float64\": \"FLOAT\",\n",
    "    \"object\": \"TEXT\",\n",
    "    \"bool\": \"BOOLEAN\"\n",
    "}\n",
    "\n",
    "# Define the table schema with caseid and facid as PRIMARY KEYS\n",
    "create_table_query = f\"CREATE TABLE IF NOT EXISTS {table_name} (\"\n",
    "for col, dtype in zip(columns, data_types):\n",
    "    mysql_type = dtype_mapping.get(str(dtype), \"TEXT\")  # Default to TEXT if unknown\n",
    "    create_table_query += f\"`{col}` {mysql_type}, \"\n",
    "\n",
    "# Define composite primary key (caseid, facid)\n",
    "create_table_query += \"PRIMARY KEY (`caseid`, `facid`));\"\n",
    "\n",
    "# Execute the table creation query\n",
    "cursor.execute(create_table_query)\n",
    "conn.commit()\n",
    "\n",
    "# Insert data into the table\n",
    "insert_query = f\"INSERT IGNORE INTO {table_name} ({', '.join(columns)}) VALUES ({', '.join(['%s'] * len(columns))})\"\n",
    "# iteratively adds rows to the table\n",
    "for _, row in df_part4.iterrows():\n",
    "    cursor.execute(insert_query, tuple(row))\n",
    "\n",
    "# Commit and close the connection\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"Data successfully loaded into MySQL database.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "database: dawn   \n",
    "Drug Abuse Warning Network (DAWN) \n",
    "\n",
    "creating schema, and importing data \n",
    "\n",
    "table name = 'data'\n",
    "\n",
    "primary key = 'CASEID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSV file has been successfully converted to CSV and saved at: C:\\Users\\darre\\OneDrive\\Documents\\ADS\\ADS 507 Data Engineering\\data\\Drug Abuse Warning Network (DAWN) ICPSR_34565\\DS0001\\34565-0001-Data.csv\n"
     ]
    }
   ],
   "source": [
    "# convert DAWN data TSV to CSV\n",
    "\n",
    "# Define the file paths \n",
    "tsv_file_path = r'C:\\Users\\darre\\OneDrive\\Documents\\ADS\\ADS 507 Data Engineering\\data\\Drug Abuse Warning Network (DAWN) ICPSR_34565\\DS0001\\34565-0001-Data.tsv'\n",
    "csv_file_path = r'C:\\Users\\darre\\OneDrive\\Documents\\ADS\\ADS 507 Data Engineering\\data\\Drug Abuse Warning Network (DAWN) ICPSR_34565\\DS0001\\34565-0001-Data.csv'\n",
    "\n",
    "# Open the TSV file for reading and the CSV file for writing\n",
    "with open(tsv_file_path, 'r', newline='', encoding='utf-8') as tsv_file, \\\n",
    "     open(csv_file_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "    \n",
    "    # Create a TSV reader and a CSV writer\n",
    "    tsv_reader = csv.reader(tsv_file, delimiter='\\t')\n",
    "    csv_writer = csv.writer(csv_file, delimiter=',')\n",
    "\n",
    "    # Iterate over each row in the TSV file and write it to the CSV file\n",
    "    for row in tsv_reader:\n",
    "        csv_writer.writerow(row)\n",
    "\n",
    "print(f\"TSV file has been successfully converted to CSV and saved at: {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import the table of the drug codes and drug labels into DAWN database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "InterfaceError",
     "evalue": "2013: Lost connection to MySQL server during query",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInterfaceError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 27\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Create the table in the DAWN database if it doesn't exist\u001b[39;00m\n\u001b[0;32m     21\u001b[0m create_table_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124mCREATE TABLE IF NOT EXISTS druglookup (\u001b[39m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124m    Value INT PRIMARY KEY,\u001b[39m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124m    Drug_Label VARCHAR(255) NOT NULL\u001b[39m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124m);\u001b[39m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 27\u001b[0m cursor\u001b[38;5;241m.\u001b[39mexecute(create_table_query)\n\u001b[0;32m     28\u001b[0m conn\u001b[38;5;241m.\u001b[39mcommit()\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Construct SQL INSERT statements using parameterized queries\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\cursor.py:416\u001b[0m, in \u001b[0;36mMySQLCursor.execute\u001b[1;34m(self, operation, params, map_results)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executed_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stmt_partition[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle_stmts\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executed \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stmt_partition[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle_stmts\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mpopleft()\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m map_results\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stmt_partition[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmappable_stmt\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    413\u001b[0m )\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_result(\n\u001b[1;32m--> 416\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mcmd_query(\n\u001b[0;32m    417\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stmt_partition[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmappable_stmt\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    418\u001b[0m         read_timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_timeout,\n\u001b[0;32m    419\u001b[0m         write_timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_timeout,\n\u001b[0;32m    420\u001b[0m     )\n\u001b[0;32m    421\u001b[0m )\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\opentelemetry\\context_propagation.py:106\u001b[0m, in \u001b[0;36mwith_context_propagation.<locals>.wrapper\u001b[1;34m(cnx, *args, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m     cnx\u001b[38;5;241m.\u001b[39mquery_attrs_append(value\u001b[38;5;241m=\u001b[39m(TRACEPARENT_HEADER_NAME, tp_header))\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 106\u001b[0m     result \u001b[38;5;241m=\u001b[39m method(cnx, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tp_header \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\utils.py:742\u001b[0m, in \u001b[0;36mhandle_read_write_timeout.<locals>.decorator.<locals>.handle_cnx_method\u001b[1;34m(cnx, *args, **kwargs)\u001b[0m\n\u001b[0;32m    740\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, \u001b[38;5;167;01mTimeoutError\u001b[39;00m):\n\u001b[0;32m    741\u001b[0m     cnx\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m--> 742\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\utils.py:738\u001b[0m, in \u001b[0;36mhandle_read_write_timeout.<locals>.decorator.<locals>.handle_cnx_method\u001b[1;34m(cnx, *args, **kwargs)\u001b[0m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(cnx_method)\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhandle_cnx_method\u001b[39m(\n\u001b[0;32m    735\u001b[0m     cnx: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMySQLConnectionAbstract\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[0;32m    736\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 738\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cnx_method(cnx, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    739\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    740\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, \u001b[38;5;167;01mTimeoutError\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\connection.py:938\u001b[0m, in \u001b[0;36mMySQLConnection.cmd_query\u001b[1;34m(self, query, raw, buffered, raw_as_string, **kwargs)\u001b[0m\n\u001b[0;32m    934\u001b[0m     read_timeout \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread_timeout\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    935\u001b[0m     write_timeout \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwrite_timeout\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    937\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_result(\n\u001b[1;32m--> 938\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_cmd(\n\u001b[0;32m    939\u001b[0m             ServerCmd\u001b[38;5;241m.\u001b[39mQUERY,\n\u001b[0;32m    940\u001b[0m             query,\n\u001b[0;32m    941\u001b[0m             read_timeout\u001b[38;5;241m=\u001b[39mread_timeout,\n\u001b[0;32m    942\u001b[0m             write_timeout\u001b[38;5;241m=\u001b[39mwrite_timeout,\n\u001b[0;32m    943\u001b[0m         ),\n\u001b[0;32m    944\u001b[0m         read_timeout,\n\u001b[0;32m    945\u001b[0m         write_timeout,\n\u001b[0;32m    946\u001b[0m     )\n\u001b[0;32m    947\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ProgrammingError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    948\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m err\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3948\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading local data is disabled\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m err\u001b[38;5;241m.\u001b[39mmsg:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\utils.py:742\u001b[0m, in \u001b[0;36mhandle_read_write_timeout.<locals>.decorator.<locals>.handle_cnx_method\u001b[1;34m(cnx, *args, **kwargs)\u001b[0m\n\u001b[0;32m    740\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, \u001b[38;5;167;01mTimeoutError\u001b[39;00m):\n\u001b[0;32m    741\u001b[0m     cnx\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m--> 742\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\utils.py:738\u001b[0m, in \u001b[0;36mhandle_read_write_timeout.<locals>.decorator.<locals>.handle_cnx_method\u001b[1;34m(cnx, *args, **kwargs)\u001b[0m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(cnx_method)\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhandle_cnx_method\u001b[39m(\n\u001b[0;32m    735\u001b[0m     cnx: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMySQLConnectionAbstract\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[0;32m    736\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 738\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cnx_method(cnx, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    739\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    740\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, \u001b[38;5;167;01mTimeoutError\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\connection.py:514\u001b[0m, in \u001b[0;36mMySQLConnection._send_cmd\u001b[1;34m(self, command, argument, packet_number, packet, expect_response, compressed_packet_number, read_timeout, write_timeout)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    507\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_socket\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m    508\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_protocol\u001b[38;5;241m.\u001b[39mmake_command(command, packet \u001b[38;5;129;01mor\u001b[39;00m argument),\n\u001b[0;32m    509\u001b[0m         packet_number,\n\u001b[0;32m    510\u001b[0m         compressed_packet_number,\n\u001b[0;32m    511\u001b[0m         write_timeout \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_timeout,\n\u001b[0;32m    512\u001b[0m     )\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 514\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_socket\u001b[38;5;241m.\u001b[39mrecv(read_timeout \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_timeout)\n\u001b[0;32m    515\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m expect_response\n\u001b[0;32m    516\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    517\u001b[0m     )\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OperationalError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMySQL Connection not available\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\network.py:669\u001b[0m, in \u001b[0;36mMySQLSocket.recv\u001b[1;34m(self, read_timeout)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m _:\n\u001b[0;32m    667\u001b[0m     \u001b[38;5;66;03m# Ignore the OSError as the socket might not be setup properly\u001b[39;00m\n\u001b[0;32m    668\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m--> 669\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_netbroker\u001b[38;5;241m.\u001b[39mrecv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maddress)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\network.py:236\u001b[0m, in \u001b[0;36mNetworkBrokerPlain.recv\u001b[1;34m(self, sock, address)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Receive `one` packet from the MySQL server.\"\"\"\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# Read the header of the MySQL packet\u001b[39;00m\n\u001b[1;32m--> 236\u001b[0m     header \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recv_chunk(sock, size\u001b[38;5;241m=\u001b[39mPACKET_HEADER_LENGTH)\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;66;03m# Pull the payload length and sequence id\u001b[39;00m\n\u001b[0;32m    239\u001b[0m     payload_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pktnr \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    240\u001b[0m         struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<I\u001b[39m\u001b[38;5;124m\"\u001b[39m, header[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\x00\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    241\u001b[0m         header[\u001b[38;5;241m3\u001b[39m],\n\u001b[0;32m    242\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\network.py:183\u001b[0m, in \u001b[0;36mNetworkBrokerPlain._recv_chunk\u001b[1;34m(self, sock, size)\u001b[0m\n\u001b[0;32m    181\u001b[0m read \u001b[38;5;241m=\u001b[39m sock\u001b[38;5;241m.\u001b[39mrecv_into(pkt_view, size)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 183\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InterfaceError(errno\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2013\u001b[39m)\n\u001b[0;32m    184\u001b[0m pkt_view \u001b[38;5;241m=\u001b[39m pkt_view[read:]\n\u001b[0;32m    185\u001b[0m size \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m read\n",
      "\u001b[1;31mInterfaceError\u001b[0m: 2013: Lost connection to MySQL server during query"
     ]
    }
   ],
   "source": [
    "# Define file path\n",
    "file_path = r\"C:/Users/darre/OneDrive/Documents/ADS/ADS 507 Data Engineering/data/Drug Abuse Warning Network (DAWN) ICPSR_34565/drug_lookup.csv\"\n",
    "\n",
    "# Read CSV into DataFrame\n",
    "drug_lookup_df = pd.read_csv(file_path)\n",
    "\n",
    "# Database connection details\n",
    "db_config = {\n",
    "    \"host\": \"mysqldchen.mysql.database.azure.com\",\n",
    "    \"user\": \"dchenAdmin\",\n",
    "    \"port\": 3306,\n",
    "    \"password\": \"507password!\",\n",
    "    \"database\": \"dawn\"\n",
    "}\n",
    "\n",
    "# Connect to MySQL database\n",
    "conn = mysql.connector.connect(**db_config)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create the table in the DAWN database if it doesn't exist\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS druglookup (\n",
    "    Value INT PRIMARY KEY,\n",
    "    Drug_Label VARCHAR(255) NOT NULL\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(create_table_query)\n",
    "conn.commit()\n",
    "\n",
    "# Construct SQL INSERT statements using parameterized queries\n",
    "insert_query = \"\"\"\n",
    "INSERT INTO druglookup (Value, Drug_Label)\n",
    "VALUES (%s, %s)\n",
    "\"\"\"\n",
    "\n",
    "# Execute batch insert\n",
    "for row in drug_lookup_df.itertuples(index=False):\n",
    "    cursor.execute(insert_query, (row.Value, row.Drug_Label))\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# Close the connection\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"CSV file successfully imported into dawn.druglookup.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drug Abuse Warning Network (DAWN) Data load \n",
    "\n",
    "Due to large dataset size 229,212 records with 285 columns, use BULK INSERT.  \n",
    "\n",
    "1. Azure Created Storage Account (resource) and uploaded CSV file. \n",
    "2. \n",
    "\n",
    "\n",
    "Option 1: Use BULK INSERT (Recommended for Large Data)\n",
    "\n",
    "    Enable Bulk Insert:\n",
    "\n",
    "EXEC sp_configure 'show advanced options', 1;\n",
    "RECONFIGURE;\n",
    "EXEC sp_configure 'Ad Hoc Distributed Queries', 1;\n",
    "RECONFIGURE;\n",
    "\n",
    "Load the CSV from Azure Blob Storage:\n",
    "\n",
    "BULK INSERT er_data\n",
    "FROM 'https://ads507storage.blob.core.windows.net/container1/34565-0001-Data.csv'\n",
    "WITH (\n",
    "    DATA_SOURCE = 'MyAzureBlobStorage',\n",
    "    FORMAT = 'CSV',\n",
    "    FIRSTROW = 2,  -- Skip header\n",
    "    FIELDTERMINATOR = ',',\n",
    "    ROWTERMINATOR = '\\n',\n",
    "    TABLOCK\n",
    ");\n",
    "\n",
    "\n",
    "Create an External Data Source (One-Time Setup):\n",
    "\n",
    "CREATE DATABASE SCOPED CREDENTIAL MyAzureCredential\n",
    "WITH IDENTITY = 'SHARED ACCESS SIGNATURE',\n",
    "SECRET = 'your_sas_token';\n",
    "\n",
    "CREATE EXTERNAL DATA SOURCE MyAzureBlobStorage\n",
    "WITH (\n",
    "    TYPE = BLOB_STORAGE,\n",
    "    LOCATION = 'https://ads507storage.blob.core.windows.net/csv-uploads',\n",
    "    CREDENTIAL = MyAzureCredential\n",
    ");\n",
    "\n",
    "Now, BULK INSERT will work with your Blob Storage!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Table created successfully.\n",
      " Inserted 1000 rows...\n",
      " Inserted 2000 rows...\n",
      " Inserted 3000 rows...\n",
      " Inserted 4000 rows...\n",
      " Inserted 5000 rows...\n",
      " All records inserted successfully.\n"
     ]
    }
   ],
   "source": [
    "# Database connection details\n",
    "db_config = {\n",
    "    \"host\": \"mysqldchen.mysql.database.azure.com\",\n",
    "    \"user\": \"dchenAdmin\",\n",
    "    \"port\": 3306,\n",
    "    \"password\": \"507password!\",\n",
    "    \"database\": \"dawn\"\n",
    "}\n",
    "\n",
    "# Connect to MySQL database\n",
    "conn = mysql.connector.connect(**db_config)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Load CSV file\n",
    "csv_file = r\"C:\\Users\\darre\\OneDrive\\Documents\\ADS\\ADS 507 Data Engineering\\data\\Drug Abuse Warning Network (DAWN) ICPSR_34565\\DS0001\\34565-0001-Data.csv\"\n",
    "\n",
    "# Read only first 5000 rows from CSV\n",
    "dawn_df = pd.read_csv(csv_file, nrows=5000)\n",
    "\n",
    "# Adjust column names\n",
    "dawn_df.columns = dawn_df.columns.str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "table_name = \"er_data\"\n",
    "\n",
    "columns = dawn_df.columns\n",
    "data_types = dawn_df.dtypes\n",
    "\n",
    "# Mapping pandas dtypes to MySQL\n",
    "dtype_mapping = {\n",
    "    \"int64\": \"INT\",\n",
    "    \"float64\": \"FLOAT\",\n",
    "    \"object\": \"TEXT\",\n",
    "    \"bool\": \"BOOLEAN\"\n",
    "}\n",
    "\n",
    "# Define the table schema dynamically\n",
    "column_definitions = \",\\n\".join([\n",
    "    f\"`{col}` {dtype_mapping.get(str(dtype), 'TEXT')} {'PRIMARY KEY' if col == 'caseid' else ''}\".strip()\n",
    "    for col, dtype in zip(columns, data_types)\n",
    "])\n",
    "\n",
    "#  FIX: Define the missing `CREATE TABLE` query\n",
    "create_table_query = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "    {column_definitions}\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# Execute table creation\n",
    "cursor.execute(create_table_query)\n",
    "conn.commit()\n",
    "print(\" Table created successfully.\")\n",
    "\n",
    "# Prepare insert query\n",
    "insert_query = f\"\"\"\n",
    "INSERT IGNORE INTO {table_name} ({', '.join(columns)})\n",
    "VALUES ({', '.join(['%s'] * len(columns))})\n",
    "\"\"\"\n",
    "\n",
    "# Convert NaNs to None for SQL compatibility\n",
    "data = dawn_df.where(pd.notnull(dawn_df), None).values.tolist()\n",
    "\n",
    "#  Improved performance: Insert data in batches\n",
    "batch_size = 1000\n",
    "for i in range(0, len(data), batch_size):\n",
    "    cursor.executemany(insert_query, data[i:i + batch_size])\n",
    "    conn.commit()\n",
    "    print(f\" Inserted {i + batch_size} rows...\")\n",
    "\n",
    "print(\" All records inserted successfully.\")\n",
    "\n",
    "# Close database connection\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Loading Data to Unified Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automation and Scheduling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: apache-airflow in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (2.10.5)\n",
      "Requirement already satisfied: alembic<2.0,>=1.13.1 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apache-airflow) (1.14.1)\n",
      "Requirement already satisfied: argcomplete>=1.10 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apache-airflow) (3.5.3)\n",
      "Requirement already satisfied: asgiref>=2.3.0 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apache-airflow) (3.8.1)\n",
      "Requirement already satisfied: attrs>=22.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from apache-airflow) (23.1.0)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from apache-airflow) (1.6.2)\n",
      "Requirement already satisfied: colorlog>=6.8.2 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apache-airflow) (6.9.0)\n",
      "Requirement already satisfied: configupdater>=3.1.1 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apache-airflow) (3.2)\n",
      "Requirement already satisfied: connexion<3.0,>=2.14.2 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from connexion[flask]<3.0,>=2.14.2->apache-airflow) (2.14.2)\n",
      "Requirement already satisfied: cron-descriptor>=1.2.24 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apache-airflow) (1.4.5)\n",
      "Requirement already satisfied: croniter>=2.0.2 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apache-airflow) (6.0.0)\n",
      "Requirement already satisfied: cryptography>=41.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from apache-airflow) (42.0.2)\n",
      "Requirement already satisfied: deprecated>=1.2.13 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apache-airflow) (1.2.18)\n",
      "Requirement already satisfied: dill>=0.2.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from apache-airflow) (0.3.7)\n",
      "Requirement already satisfied: flask-caching>=2.0.0 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apache-airflow) (2.3.1)\n",
      "Requirement already satisfied: flask-session<0.6,>=0.4.0 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apache-airflow) (0.5.0)\n",
      "Requirement already satisfied: flask-wtf>=1.1.0 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apache-airflow) (1.2.2)\n",
      "Requirement already satisfied: flask<2.3,>=2.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from apache-airflow) (2.2.5)\n",
      "Requirement already satisfied: fsspec>=2023.10.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from apache-airflow) (2023.10.0)\n",
      "Requirement already satisfied: google-re2>=1.0 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apache-airflow) (1.1.20240702)\n",
      "Requirement already satisfied: gunicorn>=20.1.0 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apache-airflow) (23.0.0)\n",
      "Requirement already satisfied: httpx>=0.25.0 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apache-airflow) (0.28.1)\n",
      "Requirement already satisfied: importlib_metadata>=6.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from apache-airflow) (7.0.1)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from apache-airflow) (2.0.1)\n",
      "Requirement already satisfied: jinja2>=3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from apache-airflow) (3.1.3)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from apache-airflow) (4.19.2)\n",
      "Requirement already satisfied: lazy-object-proxy>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from apache-airflow) (1.6.0)\n",
      "Requirement already satisfied: linkify-it-py>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from apache-airflow) (2.0.0)\n",
      "Requirement already satisfied: lockfile>=0.12.2 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apache-airflow) (0.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from apache-airflow) (2.2.0)\n",
      "Requirement already satisfied: markupsafe>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from apache-airflow) (2.1.3)\n",
      "Requirement already satisfied: marshmallow-oneofschema>=2.0.1 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apache-airflow) (3.1.1)\n",
      "Requirement already satisfied: mdit-py-plugins>=0.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from apache-airflow) (0.3.0)\n",
      "Requirement already satisfied: methodtools>=0.4.7 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apache-airflow) (0.4.7)\n",
      "Requirement already satisfied: opentelemetry-api>=1.24.0 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apache-airflow) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp>=1.24.0 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apache-airflow) (1.30.0)\n",
      "Requirement already satisfied: packaging>=23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from apache-airflow) (23.1)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from apache-airflow) (0.10.3)\n",
      "Requirement already satisfied: pendulum<4.0,>=2.1.2 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apache-airflow) (3.0.0)\n",
      "Requirement already satisfied: pluggy>=1.5.0 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apache-airflow) (1.5.0)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from apache-airflow) (5.9.0)\n",
      "Requirement already satisfied: pygments>=2.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from apache-airflow) (2.15.1)\n",
      "Requirement already satisfied: pyjwt>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from apache-airflow) (2.4.0)\n",
      "Requirement already satisfied: python-daemon>=3.0.0 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apache-airflow) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from apache-airflow) (2.8.2)\n",
      "Requirement already satisfied: python-nvd3>=0.15.0 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apache-airflow) (0.16.0)\n",
      "Requirement already satisfied: python-slugify>=5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from apache-airflow) (5.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from apache-airflow) (2.31.0)\n",
      "Requirement already satisfied: requests-toolbelt>=0.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from apache-airflow) (1.0.0)\n",
      "Requirement already satisfied: rfc3339-validator>=0.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from apache-airflow) (0.1.4)\n",
      "Requirement already satisfied: rich-argparse>=1.0.0 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apache-airflow) (1.7.0)\n",
      "Requirement already satisfied: rich>=12.4.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from apache-airflow) (13.3.5)\n",
      "Requirement already satisfied: setproctitle>=1.3.3 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apache-airflow) (1.3.5)\n",
      "Requirement already satisfied: sqlalchemy<2.0,>=1.4.36 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apache-airflow) (1.4.54)\n",
      "Requirement already satisfied: sqlalchemy-jsonfield>=1.0 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apache-airflow) (1.0.2)\n",
      "Requirement already satisfied: tabulate>=0.7.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from apache-airflow) (0.9.0)\n",
      "Requirement already satisfied: tenacity!=8.2.0,>=8.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from apache-airflow) (8.2.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apache-airflow) (2.5.0)\n",
      "Requirement already satisfied: universal-pathlib!=0.2.4,>=0.2.2 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apache-airflow) (0.2.6)\n",
      "Requirement already satisfied: werkzeug<3,>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from apache-airflow) (2.2.3)\n",
      "Requirement already satisfied: apache-airflow-providers-common-compat in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apache-airflow) (1.3.0)\n",
      "Requirement already satisfied: apache-airflow-providers-common-io in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apache-airflow) (1.5.0)\n",
      "Requirement already satisfied: apache-airflow-providers-common-sql in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apache-airflow) (1.21.0)\n",
      "Requirement already satisfied: apache-airflow-providers-fab>=1.0.2 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apache-airflow) (1.5.3)\n",
      "Requirement already satisfied: apache-airflow-providers-ftp in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apache-airflow) (3.12.0)\n",
      "Requirement already satisfied: apache-airflow-providers-http in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apache-airflow) (5.0.0)\n",
      "Requirement already satisfied: apache-airflow-providers-imap in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apache-airflow) (3.8.0)\n",
      "Requirement already satisfied: apache-airflow-providers-smtp in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apache-airflow) (1.9.0)\n",
      "Requirement already satisfied: apache-airflow-providers-sqlite in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apache-airflow) (4.0.0)\n",
      "Requirement already satisfied: Mako in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from alembic<2.0,>=1.13.1->apache-airflow) (1.3.9)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\programdata\\anaconda3\\lib\\site-packages (from alembic<2.0,>=1.13.1->apache-airflow) (4.9.0)\n",
      "Requirement already satisfied: flask-appbuilder==4.5.3 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apache-airflow-providers-fab>=1.0.2->apache-airflow) (4.5.3)\n",
      "Requirement already satisfied: flask-login>=0.6.2 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apache-airflow-providers-fab>=1.0.2->apache-airflow) (0.6.3)\n",
      "Requirement already satisfied: jmespath>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from apache-airflow-providers-fab>=1.0.2->apache-airflow) (1.0.1)\n",
      "Requirement already satisfied: apispec<7,>=6.0.0 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apispec[yaml]<7,>=6.0.0->flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow) (6.8.1)\n",
      "Requirement already satisfied: colorama<1,>=0.3.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow) (0.4.6)\n",
      "Requirement already satisfied: click<9,>=8 in c:\\programdata\\anaconda3\\lib\\site-packages (from flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow) (8.1.7)\n",
      "Requirement already satisfied: email-validator>=1.0.5 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow) (2.2.0)\n",
      "Requirement already satisfied: Flask-Babel<3,>=1 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow) (2.0.0)\n",
      "Requirement already satisfied: Flask-Limiter<4,>3 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow) (3.10.1)\n",
      "Requirement already satisfied: Flask-SQLAlchemy<3,>=2.4 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow) (2.5.1)\n",
      "Requirement already satisfied: Flask-JWT-Extended<5.0.0,>=4.0.0 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow) (4.7.1)\n",
      "Requirement already satisfied: marshmallow<4,>=3.18.0 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow) (3.26.1)\n",
      "Requirement already satisfied: marshmallow-sqlalchemy<0.29.0,>=0.22.0 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow) (0.28.2)\n",
      "Requirement already satisfied: prison<1.0.0,>=0.2.1 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow) (0.2.1)\n",
      "Requirement already satisfied: sqlalchemy-utils<1,>=0.32.21 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow) (0.41.2)\n",
      "Requirement already satisfied: WTForms<4 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow) (3.2.1)\n",
      "Requirement already satisfied: clickclick<21,>=1.2 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from connexion<3.0,>=2.14.2->connexion[flask]<3.0,>=2.14.2->apache-airflow) (20.10.2)\n",
      "Requirement already satisfied: PyYAML<7,>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from connexion<3.0,>=2.14.2->connexion[flask]<3.0,>=2.14.2->apache-airflow) (6.0.1)\n",
      "Requirement already satisfied: inflection<0.6,>=0.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from connexion<3.0,>=2.14.2->connexion[flask]<3.0,>=2.14.2->apache-airflow) (0.5.1)\n",
      "Requirement already satisfied: pytz>2021.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from croniter>=2.0.2->apache-airflow) (2023.3.post1)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\programdata\\anaconda3\\lib\\site-packages (from cryptography>=41.0.0->apache-airflow) (1.16.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from deprecated>=1.2.13->apache-airflow) (1.14.1)\n",
      "Requirement already satisfied: cachelib>=0.9.0 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from flask-caching>=2.0.0->apache-airflow) (0.13.0)\n",
      "Requirement already satisfied: anyio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx>=0.25.0->apache-airflow) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx>=0.25.0->apache-airflow) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from httpx>=0.25.0->apache-airflow) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx>=0.25.0->apache-airflow) (3.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from httpcore==1.*->httpx>=0.25.0->apache-airflow) (0.14.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib_metadata>=6.5->apache-airflow) (3.17.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema>=4.18.0->apache-airflow) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema>=4.18.0->apache-airflow) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema>=4.18.0->apache-airflow) (0.10.6)\n",
      "Requirement already satisfied: uc-micro-py in c:\\programdata\\anaconda3\\lib\\site-packages (from linkify-it-py>=2.0.0->apache-airflow) (1.0.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.1.0->apache-airflow) (0.1.0)\n",
      "Requirement already satisfied: wirerope>=0.4.7 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from methodtools>=0.4.7->apache-airflow) (1.0.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc==1.30.0 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from opentelemetry-exporter-otlp>=1.24.0->apache-airflow) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http==1.30.0 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from opentelemetry-exporter-otlp>=1.24.0->apache-airflow) (1.30.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.30.0->opentelemetry-exporter-otlp>=1.24.0->apache-airflow) (1.68.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.63.2 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.30.0->opentelemetry-exporter-otlp>=1.24.0->apache-airflow) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.30.0 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.30.0->opentelemetry-exporter-otlp>=1.24.0->apache-airflow) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.30.0 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.30.0->opentelemetry-exporter-otlp>=1.24.0->apache-airflow) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-sdk~=1.30.0 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.30.0->opentelemetry-exporter-otlp>=1.24.0->apache-airflow) (1.30.0)\n",
      "Requirement already satisfied: protobuf<6.0,>=5.0 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from opentelemetry-proto==1.30.0->opentelemetry-exporter-otlp-proto-grpc==1.30.0->opentelemetry-exporter-otlp>=1.24.0->apache-airflow) (5.29.3)\n",
      "Requirement already satisfied: tzdata>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pendulum<4.0,>=2.1.2->apache-airflow) (2023.3)\n",
      "Requirement already satisfied: time-machine>=2.6.0 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from pendulum<4.0,>=2.1.2->apache-airflow) (2.16.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.0->apache-airflow) (1.16.0)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-slugify>=5.0->apache-airflow) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->apache-airflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->apache-airflow) (2.0.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from sqlalchemy<2.0,>=1.4.36->apache-airflow) (3.0.1)\n",
      "Requirement already satisfied: more-itertools>=9.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from apache-airflow-providers-common-sql->apache-airflow) (10.1.0)\n",
      "Requirement already satisfied: sqlparse>=0.5.1 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apache-airflow-providers-common-sql->apache-airflow) (0.5.3)\n",
      "Requirement already satisfied: aiohttp!=3.11.0,>=3.9.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from apache-airflow-providers-http->apache-airflow) (3.9.3)\n",
      "Requirement already satisfied: aiosqlite>=0.20.0 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from apache-airflow-providers-sqlite->apache-airflow) (0.21.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp!=3.11.0,>=3.9.2->apache-airflow-providers-http->apache-airflow) (1.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp!=3.11.0,>=3.9.2->apache-airflow-providers-http->apache-airflow) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp!=3.11.0,>=3.9.2->apache-airflow-providers-http->apache-airflow) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp!=3.11.0,>=3.9.2->apache-airflow-providers-http->apache-airflow) (1.9.3)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=41.0.0->apache-airflow) (2.21)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from anyio->httpx>=0.25.0->apache-airflow) (1.3.0)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from email-validator>=1.0.5->flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow) (2.7.0)\n",
      "Requirement already satisfied: Babel>=2.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from Flask-Babel<3,>=1->flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow) (2.11.0)\n",
      "Requirement already satisfied: limits>=3.13 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from Flask-Limiter<4,>3->flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow) (4.0.1)\n",
      "Requirement already satisfied: ordered-set<5,>4 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from Flask-Limiter<4,>3->flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow) (4.1.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in c:\\users\\darre\\appdata\\roaming\\python\\python311\\site-packages (from opentelemetry-sdk~=1.30.0->opentelemetry-exporter-otlp-proto-grpc==1.30.0->opentelemetry-exporter-otlp>=1.24.0->apache-airflow) (0.51b0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\darre\\AppData\\Roaming\\Python\\Python311\\site-packages\\airflow\\__init__.py:36: RuntimeWarning: Airflow currently can be run on POSIX-compliant Operating Systems. For development, it is regularly tested on fairly modern Linux Distros and recent versions of macOS. On Windows you can run it via WSL2 (Windows Subsystem for Linux 2) or via Linux Containers. The work to add Windows support is tracked via https://github.com/apache/airflow/issues/10388, but it is not a high priority.\n",
      "  warnings.warn(\n",
      "OSError while attempting to symlink the latest log directory\n"
     ]
    }
   ],
   "source": [
    "# Install the apache-airflow package\n",
    "# %pip install apache-airflow\n",
    "\n",
    "from airflow import DAG\n",
    "from airflow.operators.python import PythonOperator\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract():\n",
    "    print(\"Extracting data...\")\n",
    "\n",
    "def transform():\n",
    "    print(\"Transforming data...\")\n",
    "\n",
    "def load():\n",
    "    print(\"Loading data into database...\")\n",
    "\n",
    "dag = DAG(\n",
    "    'data_pipeline',\n",
    "    schedule_interval='@daily',\n",
    "    start_date=datetime(2024, 1, 1),\n",
    ")\n",
    "\n",
    "task_extract = PythonOperator(task_id='extract', python_callable=extract, dag=dag)\n",
    "task_transform = PythonOperator(task_id='transform', python_callable=transform, dag=dag)\n",
    "task_load = PythonOperator(task_id='load', python_callable=load, dag=dag)\n",
    "\n",
    "task_extract >> task_transform >> task_load\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated ETL pipline using Airflow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
